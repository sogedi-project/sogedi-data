---
title: "Data preparation"
subtitle: "Socioeconomic and Gender Disparities: A Multi-Country Study"
author: "Andreas Laffert, Research asistant"
date: today
lang: en
fontsize: 12pt
format:
  html:
    toc: true
    toc-location: right
    toc-depth: 2
    toc-expand: 2
    toc-title: Contents
    number-sections: true
    number-depth: 3
    theme:
      - cosmo
      - "../sogedi.scss"
    code-link: true
    title-block-banner: true
  pdf:
    number-sections: true
    number-depth: 3
editor_options: 
  chunk_output_type: console
---

# Presentation

This is the preparation code of the data for the project Socioeconomic and Gender Disparities: A Multi-Country Study. The prepared data is `SOGEDI_dataset_V1.sav`


```{r}
#| label: set
#| echo: false
#| message: false
#| warning: false

library(knitr)
knitr::opts_chunk$set(echo = TRUE, include = TRUE, warning = FALSE, message = FALSE)

table_format <- if(is_html_output()) {
  "html"
} else if(is_latex_output()) {
  "latex"
}
table_format2 <- if(is_html_output()) {
  T
} else if(is_latex_output()) {
  F
}

options(kableExtra.html.bsTable = T)
options(knitr.kable.NA = "")
```


# Libraries

First, we load the necessary libraries. In this case, we use `pacman::p_load` to load and call libraries in one move. 

```{r}
#| label: libraries

if (! require("pacman")) install.packages("pacman")

pacman::p_load(tidyverse,
               sjmisc, 
               here,
               sjlabelled,
               haven,
               naniar,
               car,
               kableExtra)

options(scipen=999)
rm(list = ls())

```


# Data

We load the database from the local path. Modify this later.

```{r}
#| label: data

sogedi_db <- haven::read_sav(file = here("input/data/original/SOGEDI_dataset_V1.sav"), user_na = T)

glimpse(sogedi_db)
```

We have 4,386 cases or rows and 283 variables or columns.

# Processing

## Select

We exclude variables related to attention checks, survey response time, dummy nationalities and the auxiliary variable `PrimarioÃšltimo`, which indicates whether there are duplicate cases. 


```{r}
#| label: select

db_proc <- sogedi_db %>% 
  dplyr::select(-c(matches("^(aten|time)"), 247:269, 283))

```

## Filter

We filter out cases from countries without a sufficiently large sample size for statistical analysis, retaining only those from Argentina, Chile, Colombia, Spain, and Mexico.

```{r}
#| label: filter

frq(db_proc$natio_recoded)

db_proc <- db_proc %>% 
  dplyr::filter(natio_recoded %in% c(1,3,4,9,13)) 

```

## Recode and transform

Not required. 

## Missing values

```{r, echo=FALSE}
total_na <- n_miss(db_proc) # total of NA's

prop_na <- prop_miss(db_proc)*100 # proportion of NA's

```

There is a total of `r format(total_na, big.mark = ".")` missing values in the database, which represents the `r scales::percent(prop_na, scale = 1, accuracy = 0.1)` of the total. 

```{r}
#| label: missings1
#| collapse: false

n_miss(db_proc) # total of NA's

prop_miss(db_proc)*100 # proportion of NA's
```

Let's see the number and percentage of missing values per variable:

```{r}
#| label: missings2
#| collapse: false

db_proc %>% 
  select(-c(ex_we_1, ex_we_2, in_we_1, in_we_2, 
            ex_po_1, ex_po_2, in_po_1, in_po_2,
            matches("^(greedy|punish|carin)"))) %>% 
  miss_var_summary(.) %>% 
  filter(pct_miss > 0) %>% 
  kable(.,"markdown") 
```

# Save and export

Finally, we save and export the processed database `db_proc` in `.RData`, `.dta` and `.sav` formats.

```{r}
save(db_proc, file = here("output/data/db_proc.RData"))
haven::write_dta(db_proc, path = here("output/data/db_proc.dta"))
haven::write_sav(db_proc, path = here("output/data/db_proc.sav"))
```

